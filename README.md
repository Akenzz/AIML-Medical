# HealthDesk AI â€“ Unified Medical Assistant Server

A comprehensive FastAPI-based unified server providing three integrated AI-powered medical services: disease prediction, intelligent medical chatbot, and patient consultation analysis.

## ğŸ“‹ Project Overview

HealthDesk AI is a unified microservices server that combines multiple machine learning and generative AI capabilities to provide comprehensive healthcare support. It includes:

- **Symptom-based disease prediction** using machine learning
- **Multilingual medical chatbot** powered by RAG (Retrieval-Augmented Generation)
- **Intelligent consultation analysis** for severity assessment and summarization

## ğŸ—ï¸ Architecture

The project is structured as a unified FastAPI server that mounts three separate services:

```
HealthDesk AI Server (Port 8000)
â”œâ”€â”€ /predict-disease    â†’ Symptom Checker API
â”œâ”€â”€ /medical-bot        â†’ Medical Chatbot API
â””â”€â”€ /medreach           â†’ Consultation Analysis API
```

## ğŸ“¦ Services

### 1. **Predict Disease** (`/services/predict_disease/`)
Predicts the top 3 most likely diseases based on provided symptoms using a pre-trained machine learning model.

**Key Features:**
- Quick disease prediction from symptom list
- Returns probability scores for each prediction
- Uses LightGBM model trained on medical symptom data

**Endpoints:**
- `GET /predict-disease/` â€“ Service information
- `POST /predict-disease/predict` â€“ Predict diseases from symptoms

**Request Example:**
```json
{
  "symptoms": ["fever", "cough", "headache"]
}
```

**Response Example:**
```json
{
  "predictions": [
    {"disease": "Common Cold", "probability": 0.85},
    {"disease": "Flu", "probability": 0.72},
    {"disease": "COVID-19", "probability": 0.65}
  ]
}
```

### 2. **Medical Bot** (`/services/medical_bot/`)
An intelligent medical chatbot powered by RAG that retrieves relevant medical information and maintains conversation history. Supports multiple languages including English, Hindi, Urdu, and Kannada.

**Key Features:**
- **Retrieval-Augmented Generation (RAG)** using Pinecone vector store
- **Multilingual support** with automatic language detection (English, Hindi/Urdu in Roman script, Kannada in Roman script)
- **Conversation history** per user for contextual responses
- **Dual LLM support**: Google Gemini (main responses) + Groq LLaMA (language detection)
- **Medical PDF knowledge base** integration

**Endpoints:**
- `GET /medical-bot/` â€“ Service status
- `POST /medical-bot/chat` â€“ Chat with medical assistant

**Request Example:**
```json
{
  "question": "What are the symptoms of diabetes?",
  "user_id": "user123"
}
```

**Response Example:**
```json
{
  "answer": "Diabetes symptoms include...",
  "context": ["retrieved medical document 1", "retrieved medical document 2"],
  "history": [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}],
  "detected_language": "English",
  "detected_script": "English",
  "english_translation": null
}
```

### 3. **Medreach** (`/services/medreach/`)
Analyzes patient consultation transcripts, provides medical summaries, and assesses severity levels for triage and emergency response prioritization.

**Key Features:**
- **Transcript analysis** using Google Gemini API
- **Severity assessment** with 4-level classification:
  - **Low**: Minor ailments (common cold, mild headache)
  - **Medium**: Non-urgent conditions (rash, controlled chronic issues)
  - **High**: Urgent conditions requiring prompt attention (high fever with confusion)
  - **Critical**: Life-threatening emergencies (chest pain, stroke signs, severe bleeding)
- **Intelligent summarization** of patient symptoms
- **Integration with Java backend** for database persistence

**Endpoints:**
- `GET /medreach/` â€“ Service information
- `POST /medreach/submit` â€“ Analyze consultation transcript

**Request Example:**
```json
{
  "transcript": "Patient reports chest pain radiating to the left arm..."
}
```

**Response Example:**
```json
{
  "summary": "Patient experiencing chest pain with left arm radiation",
  "severity": "Critical"
}
```

## ğŸš€ Getting Started

### Prerequisites
- Python 3.8+
- FastAPI and Uvicorn
- API keys for:
  - **Pinecone** (medical-bot)
  - **Google Generative AI** (medical-bot, medreach)
  - **Groq API** (medical-bot)
  - **LangChain** (optional, for tracing)

### Installation

1. **Clone the repository:**
   ```bash
   git clone <repository-url>
   cd HealthDesk-AI
   ```

2. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configure environment variables:**
   Create a `.env` file in the root directory with:
   ```
   # Pinecone Configuration
   PINECONE_API_KEY=your_pinecone_api_key
   PINECONE_INDEX_NAME=medical-bot

   # Google Generative AI
   GOOGLE_API_KEY=your_google_api_key
   GOOGLE_GEMINI_MODEL=gemini-2.5-flash-lite

   # Groq API
   GROQ_API_KEY=your_groq_api_key
   GROQ_MODEL=llama-3.1-8b-instant

   # Java Backend (for Medreach)
   JAVA_BACKEND_URL=http://your-java-backend-url

   # LangChain (optional)
   LANGCHAIN_API_KEY=your_langchain_api_key
   LANGCHAIN_TRACING_V2=true
   LANGCHAIN_PROJECT=Medical-bot
   ```

4. **Run the unified server:**
   ```bash
   python app.py
   ```
   Or with Uvicorn directly:
   ```bash
   uvicorn app:app --reload --port 8000
   ```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app.py                              # Main unified FastAPI server
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ predict_disease/
â”‚   â”‚   â”œâ”€â”€ app.py                      # Symptom checker API
â”‚   â”‚   â”œâ”€â”€ symptom_checker_model.joblib    # Pre-trained ML model
â”‚   â”‚   â””â”€â”€ symptom_columns.joblib      # Model feature columns
â”‚   â”œâ”€â”€ medical_bot/
â”‚   â”‚   â”œâ”€â”€ app.py                      # Medical chatbot with RAG
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ helper.py               # PDF loading & text processing utilities
â”‚   â”‚   â”‚   â””â”€â”€ prompt.py               # System prompt for medical assistant
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ medreach/
â”‚   â”‚   â”œâ”€â”€ app.py                      # Consultation analysis API
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ __init__.py
â””â”€â”€ README.md                           # This file
```

## ğŸ”§ Dependencies

Key packages used in this project:

**Core Framework:**
- `fastapi` â€“ Modern API framework
- `uvicorn[standard]` â€“ ASGI server

**ML & Data Processing:**
- `pandas` â€“ Data manipulation
- `scikit-learn` â€“ Machine learning algorithms
- `lightgbm` â€“ Gradient boosting model
- `joblib` â€“ Model serialization

**Generative AI & LLMs:**
- `langchain-google-genai` â€“ Google Gemini integration
- `langchain-groq` â€“ Groq API integration
- `langchain-community` â€“ Additional LangChain tools
- `langchain-pinecone` â€“ Pinecone vector store integration
- `langchain-huggingface` â€“ Hugging Face embeddings
- `sentence-transformers` â€“ Text embedding models
- `groq` â€“ Groq API client
- `pinecone` â€“ Vector database client

**Utilities:**
- `python-multipart` â€“ Form data handling
- `requests` â€“ HTTP client
- `python-dotenv` â€“ Environment variable management

For complete dependencies, see [requirements.txt](requirements.txt).

## ğŸ” Security Considerations

- Store API keys securely in `.env` file (never commit to version control)
- Implement authentication for production deployment
- Validate and sanitize all user inputs
- Use HTTPS in production
- Implement rate limiting for API endpoints

## ğŸ“š API Documentation

Once the server is running, access the interactive API documentation:

- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

## ğŸ¤ Features

### Multilingual Support (Medical Bot)
The medical bot automatically detects and translates:
- **English**: Standard medical queries
- **Hindi/Urdu (Roman script)**: "bukhar hai", "sir dard", "pet dard"
- **Kannada (Roman script)**: "jwaravu ide", "tale novu", "hotte novu"
- **Native scripts**: Devanagari (à¤¦à¥‡à¤µà¤¨à¤¾à¤—à¤°à¥€), Arabic (Ø¹Ø±Ø¨ÙŠ), Kannada (à²•à²¨à³à²¨à²¡)

### RAG Implementation (Medical Bot)
- Retrieves relevant medical documents from Pinecone vector store
- Combines retrieved context with LLM for accurate, sourced responses
- Maintains conversation history for contextual understanding
- Default retrieval: Top 2 most similar documents

### Severity Assessment (Medreach)
Intelligent 4-level severity classification based on:
- Symptom descriptions
- Clinical indicators
- Emergency red flags
- Medical urgency guidelines

## âš™ï¸ Configuration

### Medical Bot Configuration
- **Chunk Size**: 1,300 characters with 230-character overlap
- **Retrieval Type**: Similarity-based (k=2)
- **Primary LLM**: Google Gemini
- **Fallback LLM**: Groq LLaMA

### Predict Disease Configuration
- **Model Type**: LightGBM classifier
- **Output**: Top 3 predictions with probabilities

## ğŸ¤– How It Works

### Workflow for Medical Bot

1. **User Query Input**: Patient sends a medical question
2. **Language Detection**: LLaMA detects the language and script
3. **Translation**: Convert to English if needed
4. **RAG Retrieval**: Pinecone retrieves 2 most relevant medical documents
5. **LLM Response**: Gemini generates response based on context + history
6. **Response Formatting**: Return answer with context, history, and language metadata

### Workflow for Medreach

1. **Transcript Upload**: Medical conversation transcript received
2. **Analysis**: Gemini analyzes transcript
3. **Summary Generation**: Extract key symptoms and findings
4. **Severity Assessment**: Classify as Low/Medium/High/Critical
5. **Response**: Return structured analysis

### Workflow for Predict Disease

1. **Symptom Input**: User provides list of symptoms
2. **Feature Vectorization**: Convert symptoms to model-compatible format
3. **Prediction**: LightGBM model generates probability scores
4. **Ranking**: Return top 3 diseases by probability

## ğŸ“Š Performance Notes

- Medical Bot: Depends on Pinecone latency and LLM API response time
- Predict Disease: ~50-100ms per prediction (model inference)
- Medreach: Depends on Google Gemini API response time
- Conversation history maintained in-memory (consider database for production)

## ğŸ› Troubleshooting

**Model not found error:**
```
Error: Model or column file not found in services/predict_disease.
```
Ensure `symptom_checker_model.joblib` and `symptom_columns.joblib` exist in the predict_disease directory.

**API Key missing error:**
Check that all required environment variables are set in `.env` file.

**Pinecone connection error:**
Verify `PINECONE_API_KEY` and `PINECONE_INDEX_NAME` are correct.

## ğŸš¢ Deployment

### Docker Deployment
```bash
docker build -t healthdesk-ai .
docker run -p 8000:8000 --env-file .env healthdesk-ai
```

### Production Considerations
- Use a production ASGI server (e.g., Gunicorn with Uvicorn workers)
- Implement database persistence for conversation history
- Add authentication and authorization
- Set up request logging and monitoring
- Implement rate limiting
- Use environment-specific configurations

## ğŸ’¡ Example Use Cases

1. **Patient Self-Diagnosis**: Use medical bot to understand symptoms or predict disease
2. **Triage System**: Use Medreach to quickly assess patient severity
3. **Medical Support**: Chat-based guidance for common health concerns
4. **Clinical Training**: Educational tool for medical professionals
5. **Telehealth Integration**: Embed services into telemedicine platforms

## ğŸ“ Version History

- **v1.2.0** â€“ Unified server with all three services
- **v2.1.0** â€“ Predict Disease (latest)
- **v1.3.0** â€“ Medical Bot (latest)

## ğŸ“„ License

[Specify your license here]

## ğŸ‘¥ Contributing

[Add contribution guidelines here]

## ğŸ“§ Support

For issues, questions, or contributions, please [contact information/issue tracker].

---

**Built with â¤ï¸ for better healthcare accessibility**
